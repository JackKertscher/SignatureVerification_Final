{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "from keras import ops\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import regularizers\n",
    "\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage as ski\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Resized Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORG_DATA_PATH = \"signatures/resized_forg\"\n",
    "ORG_DATA_PATH = \"signatures/resized_org\"\n",
    "\n",
    "\n",
    "'''\n",
    "For each image, \n",
    "    converts to black and white, \n",
    "    turns into an np array, and \n",
    "    stores it in dict as:\n",
    "        forgeries[IMAGE_NAME]\n",
    "            or\n",
    "        originals[IMAGE_NAME]\n",
    "'''\n",
    "forgeries = {}\n",
    "for filename in os.listdir(FORG_DATA_PATH):\n",
    "    name = filename.split(\".\")[0]\n",
    "    filepath = FORG_DATA_PATH + \"/\" + filename\n",
    "    with Image.open(filepath) as img:\n",
    "        # Manual conversion to B&W using otsu thresholding\n",
    "        greyscale = img.convert('L')\n",
    "        threshold = ski.filters.threshold_otsu(np.asarray(greyscale))\n",
    "        thresholded = greyscale.point( lambda p: 255 if p > threshold else 0 )\n",
    "        black_and_white = thresholded.convert('1')  \n",
    "\n",
    "        forgeries[name] = np.array(black_and_white)\n",
    "\n",
    "originals = {}\n",
    "for filename in os.listdir(ORG_DATA_PATH):\n",
    "    name = filename.split(\".\")[0]\n",
    "    filepath = ORG_DATA_PATH + \"/\" + filename\n",
    "    with Image.open(filepath) as img:\n",
    "        # Manual conversion to B&W using otsu thresholding\n",
    "        greyscale = img.convert('L')\n",
    "        hreshold = ski.filters.threshold_otsu(np.asarray(greyscale))\n",
    "        thresholded = greyscale.point( lambda p: 255 if p > threshold else 0 )\n",
    "        black_and_white = thresholded.convert('1') \n",
    "\n",
    "        originals[name] = np.array(black_and_white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format into testing/training data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    \\nCurrent format:\\nsig_dict = {\\n    [user number] : { \\n            \"forgeries\" : {\"1\": [first_forgery],\\n                           \"2\": [second_forgery],\\n                           ...},\\n            \"originals\" : \"1\": [first_original],\\n                           \"2\": [second_original],\\n                           ...}\\n            }\\n    \"2\" : { ...\\n    }\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reformat into sig_dict[user_id] -> {\"originals\": {}, \"forgeries\", {}}\n",
    "\n",
    "sig_dict = {}\n",
    "\n",
    "for key in forgeries.keys():\n",
    "    user_id = key.split(\"_\")[1]\n",
    "    sig_number = key.split(\"_\")[2]\n",
    "\n",
    "    if user_id in sig_dict.keys():\n",
    "        sig_dict[user_id][\"forgeries\"][sig_number] = forgeries[key]\n",
    "    else:\n",
    "        sig_dict[user_id] = {\"forgeries\" : {sig_number : forgeries[key]},\n",
    "                             \"originals\" : {}\n",
    "                             }\n",
    "\n",
    "for key in originals.keys():\n",
    "    user_id = key.split(\"_\")[1]\n",
    "    sig_number = key.split(\"_\")[2]\n",
    "    sig_dict[user_id][\"originals\"][sig_number] = originals[key]\n",
    "    # sig_dict[user_id][\"originals\"][sig_number] = \"org\"\n",
    "\n",
    "'''    \n",
    "Current format:\n",
    "sig_dict = {\n",
    "    [user number] : { \n",
    "            \"forgeries\" : {\"1\": [first_forgery],\n",
    "                           \"2\": [second_forgery],\n",
    "                           ...},\n",
    "            \"originals\" : \"1\": [first_original],\n",
    "                           \"2\": [second_original],\n",
    "                           ...}\n",
    "            }\n",
    "    \"2\" : { ...\n",
    "    }\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = [], []\n",
    "x_test, y_test = [], []\n",
    "\n",
    "# labels: 1 == genuine:genuine, 0 == genuine:forgery\n",
    "# The first 44 users will be train and the remaining 11 will be in testing\n",
    "\n",
    "for user_id in sig_dict.keys():\n",
    "    user_sigs = sig_dict[user_id]\n",
    "\n",
    "    if int(user_id) <= 44: \n",
    "        # TRAINING DATA\n",
    "\n",
    "        for reference_sig_id in user_sigs[\"originals\"]:\n",
    "            reference_original = user_sigs[\"originals\"][reference_sig_id]\n",
    "\n",
    "            # Iterate through all other signatures and make a data point\n",
    "            # Originals\n",
    "            for org_id in user_sigs[\"originals\"]:\n",
    "                if org_id == reference_sig_id: continue\n",
    "                org_image = user_sigs[\"originals\"][org_id]\n",
    "\n",
    "                x_train.append((reference_original, org_image))\n",
    "                y_train.append(1)\n",
    "            \n",
    "            # Forgeries\n",
    "            for forg_id in user_sigs[\"forgeries\"]:\n",
    "                forg_image = user_sigs[\"forgeries\"][forg_id]\n",
    "\n",
    "                x_train.append((reference_original, forg_image))\n",
    "                y_train.append(0)\n",
    "\n",
    "\n",
    "    else:\n",
    "        #TESTING\n",
    "        \n",
    "        for reference_sig_id in user_sigs[\"originals\"]:\n",
    "            reference_original = user_sigs[\"originals\"][reference_sig_id]\n",
    "\n",
    "            # Iterate through all other signatures and make a data point\n",
    "            # Originals\n",
    "            for org_id in user_sigs[\"originals\"]:\n",
    "                if org_id == reference_sig_id: continue\n",
    "                org_image = user_sigs[\"originals\"][org_id]\n",
    "\n",
    "                x_test.append((reference_original, org_image))\n",
    "                y_test.append(1)\n",
    "            \n",
    "            # Forgeries\n",
    "            for forg_id in user_sigs[\"forgeries\"]:\n",
    "                forg_image = user_sigs[\"forgeries\"][forg_id]\n",
    "\n",
    "                x_test.append((reference_original, forg_image))\n",
    "                y_test.append(0)\n",
    "\n",
    "x_train = np.array(x_train, dtype='float32')\n",
    "y_train = np.array(y_train, dtype='float32')\n",
    "x_test = np.array(x_test, dtype='float32')\n",
    "y_test = np.array(y_test, dtype='float32')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = x_train[:, 0]\n",
    "x_train_2 = x_train[:, 1]\n",
    "\n",
    "x_test_1 = x_test[:, 0]\n",
    "x_test_2 = x_test[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "def euclidean_dist(vectors):\n",
    "    x, y = vectors\n",
    "    return ops.sqrt(ops.maximum(ops.sum(ops.square(x - y), axis=1, keepdims=True), keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "def loss(margin=1):\n",
    "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
    "    #                         true_value * square( max(margin-prediction, 0) ))\n",
    "    @keras.saving.register_keras_serializable()\n",
    "    def contrastive_loss(y_true, y_pred):\n",
    "        return ops.mean((1 - y_true) * ops.square(y_pred) + (y_true) * ops.square(ops.maximum(margin - (y_pred), 0)))\n",
    "\n",
    "    return contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_network = keras.saving.load_model('best_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 375ms/step\n",
      "False Positive Rate (forgeries predicted as genuine): 32.62%\n",
      "False Negative Rate (genuines predicted as forgery): 23.55%\n"
     ]
    }
   ],
   "source": [
    "# Predict similarity scores on the test set\n",
    "y_pred = siamese_network.predict((x_test_1, x_test_2)).flatten()\n",
    "\n",
    "# Set a threshold for classification (e.g., 0.5)\n",
    "threshold = 0.5\n",
    "\n",
    "# Initialize counters\n",
    "total_forgeries = 0\n",
    "false_positives = 0\n",
    "\n",
    "total_genuines = 0\n",
    "false_negatives = 0\n",
    "\n",
    "# Go through each prediction\n",
    "for i in range(len(y_test)):\n",
    "    actual_label = y_test[i]     # 0 = forgery, 1 = genuine\n",
    "    predicted_score = y_pred[i]  # closer to 1 = predicted genuine, closer to 0 = predicted forgery\n",
    "\n",
    "    if actual_label == 0:  # It's a forgery\n",
    "        total_forgeries += 1\n",
    "        if predicted_score >= threshold:\n",
    "            false_positives += 1  # Predicted genuine, but it's a forgery\n",
    "\n",
    "    elif actual_label == 1:  # It's genuine\n",
    "        total_genuines += 1\n",
    "        if predicted_score < threshold:\n",
    "            false_negatives += 1  # Predicted forgery, but it's genuine\n",
    "\n",
    "# Compute rates\n",
    "fp_rate = false_positives / total_forgeries if total_forgeries > 0 else 0\n",
    "fn_rate = false_negatives / total_genuines if total_genuines > 0 else 0\n",
    "\n",
    "# Print results\n",
    "print(f\"False Positive Rate (forgeries predicted as genuine): {fp_rate * 100:.2f}%\")\n",
    "print(f\"False Negative Rate (genuines predicted as forgery): {fn_rate * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralnetworks2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
